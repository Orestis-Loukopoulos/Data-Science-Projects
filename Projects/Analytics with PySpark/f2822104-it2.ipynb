{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f88d18d-fe8c-40f2-a045-39de9f230085",
   "metadata": {},
   "source": [
    "## Loukopoulos Orestis | f2822104"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183d680c-19aa-4825-a36b-9388dde26ef9",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "0b460d61-7495-475e-997c-b10c2e437154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"books\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c8c770-a996-4384-912d-2b8c84796b73",
   "metadata": {},
   "source": [
    "* We will load the json file in a dataframe(`df1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "766996fd-ba8d-499b-ba25-6e98c095052f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = spark.read.json(\"Assignment Spark/books_5000.json\")\n",
    "type(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d54b4e-5a39-4031-82a1-58cf6f8e2544",
   "metadata": {},
   "source": [
    "* We will check the data types of dataframe's variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "3383db8d-bc7e-4abf-955b-d6ecca3c7aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('asin', 'string'),\n",
       " ('authors', 'array<struct<author_id:string,role:string>>'),\n",
       " ('average_rating', 'string'),\n",
       " ('book_id', 'string'),\n",
       " ('country_code', 'string'),\n",
       " ('description', 'string'),\n",
       " ('edition_information', 'string'),\n",
       " ('format', 'string'),\n",
       " ('image_url', 'string'),\n",
       " ('is_ebook', 'string'),\n",
       " ('isbn', 'string'),\n",
       " ('isbn13', 'string'),\n",
       " ('kindle_asin', 'string'),\n",
       " ('language_code', 'string'),\n",
       " ('link', 'string'),\n",
       " ('num_pages', 'string'),\n",
       " ('popular_shelves', 'array<struct<count:string,name:string>>'),\n",
       " ('publication_day', 'string'),\n",
       " ('publication_month', 'string'),\n",
       " ('publication_year', 'string'),\n",
       " ('publisher', 'string'),\n",
       " ('ratings_count', 'string'),\n",
       " ('series', 'array<string>'),\n",
       " ('similar_books', 'array<string>'),\n",
       " ('text_reviews_count', 'string'),\n",
       " ('title', 'string'),\n",
       " ('title_without_series', 'string'),\n",
       " ('url', 'string'),\n",
       " ('work_id', 'string')]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eddc0a8-5cff-479c-8d1e-a97902e8f0df",
   "metadata": {},
   "source": [
    "* First of all, we will convert the datatype of column `average_rating` from string to numeric type, in order to perfrom our calculations correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "cf339a3e-d3bd-43ef-9cac-b8cd39a59148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "df1 = df1.withColumn('average_rating',col('average_rating').cast('double'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a2e48a-cec4-4c90-97b7-75a8d9805bde",
   "metadata": {},
   "source": [
    "* We select the columns that we want to display. Then we take only the books that have a title that begins with an \"L\". We sort those observations based on their average rating in descending order. We display only the first row, which is the book with the max `average_rating`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "71c1b7fe-8d12-457b-8068-e7da9516bda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+--------------------+\n",
      "|average_rating| book_id|               title|\n",
      "+--------------+--------+--------------------+\n",
      "|          4.73|23342149|Locke and Key: Cl...|\n",
      "+--------------+--------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select(df1.average_rating, df1.book_id, df1.title).where(df1.title.startswith('L')).sort(df1.average_rating.desc()).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6991cad2-24ab-43e9-b831-56579626763b",
   "metadata": {},
   "source": [
    "* The following code returns the average `average_rating` of the books that their title starts with an \"O\" which is the *second* letter of your my last name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "d5fe7459-f2e5-44af-bbae-87236cffc31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|avg(average_rating)|\n",
      "+-------------------+\n",
      "| 3.9694047619047628|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#We converted our DataFrame to a table\n",
    "df1.createOrReplaceTempView(\"df1\")\n",
    "\n",
    "#The following query returns the average \"average_rating\" of the books\n",
    "sql_way = spark.sql(\"\"\"\n",
    "  SELECT avg(average_rating)\n",
    "  FROM df1\n",
    "  WHERE title LIKE 'O%'\n",
    "  \"\"\")\n",
    "\n",
    "sql_way.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc7297-4855-4dca-b576-066e465e3b76",
   "metadata": {},
   "source": [
    "* First of all, we will convert the datatype of column `num_pages` from string to numeric type, in order to find the max correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "9a667c69-858a-498a-84d0-3530a2245fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.withColumn('num_pages',col('num_pages').cast('double'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c878f7b7-8146-4330-93a9-fbb5fe045d40",
   "metadata": {},
   "source": [
    "* The following code returns the `book_id` and the `title` of the Paperback books with the most pages, when only books with title starting with the letter \"U\", which is the third letter of my last name, are considered.\n",
    "\n",
    "* We select the columns that we want to display. Then we take only the books that have a `title` that begins with an \"U\" and a Paperback `format`. We sort those books based on their number of pages (e.g., `num_pages`) in descending order. We display only the first row, which is the book with the max `num_pages`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "33b0fecc-3229-4b86-a41c-2e6fac4dbf13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-----------------+---------+\n",
      "|num_pages|book_id|            title|   format|\n",
      "+---------+-------+-----------------+---------+\n",
      "|    256.0|1940344|Usagi Yojimbo #12|Paperback|\n",
      "+---------+-------+-----------------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select(df1.num_pages, df1.book_id, df1.title, df1.format).where((df1.title.startswith('U')) & (df1.format=='Paperback')).sort(df1.num_pages.desc()).show(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

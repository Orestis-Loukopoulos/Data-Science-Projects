{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20e82f19-a8db-41aa-978b-c137873d1f29",
   "metadata": {},
   "source": [
    "## Loukopoulos Orestis | f2822104"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068172a6-e8f0-4738-a7e6-b354d92b9131",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "e664ddc3-6629-489e-bc5f-753a424c1437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"books\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c67b584-9421-4f67-afce-81e2092ab6b7",
   "metadata": {},
   "source": [
    "* We will load the json file in a dataframe(`df1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "766996fd-ba8d-499b-ba25-6e98c095052f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = spark.read.json(\"Assignment Spark/books_5000.json\")\n",
    "type(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e868e469-c045-4d6f-a634-b4a4615de0ee",
   "metadata": {},
   "source": [
    "* In the following table we can see the columns that we will use for our regression model. The variable `average_rating` will be our response variable that we will try to predict, while the rest variables are the input variables (covariates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "f0d5b772-974b-4731-ae9e-255f45e2841d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+---------+-------------+----------------+\n",
      "|average_rating|language_code|num_pages|ratings_count|publication_year|\n",
      "+--------------+-------------+---------+-------------+----------------+\n",
      "|          4.12|             |         |            1|                |\n",
      "|          3.94|          fre|         |           16|            2016|\n",
      "|          4.28|          eng|      146|           51|            2012|\n",
      "|          4.05|          eng|         |            6|                |\n",
      "|          4.06|        en-US|      272|           51|            1997|\n",
      "|          3.44|             |      206|           46|            2007|\n",
      "|          4.15|          eng|      224|           39|            2016|\n",
      "|          3.16|             |      160|           38|            2016|\n",
      "|          3.51|             |      160|           44|            2016|\n",
      "|          4.00|             |      144|           32|            2016|\n",
      "|          4.41|          kor|      212|          133|            2014|\n",
      "|          3.16|          eng|      144|          114|            2011|\n",
      "|          4.41|          eng|      200|          149|            2012|\n",
      "|          4.39|             |      230|          152|            2012|\n",
      "|          1.86|             |         |           64|                |\n",
      "|          4.31|          jpn|      157|          174|            2013|\n",
      "|          4.43|          spa|      224|           30|            2006|\n",
      "|          4.38|          zho|      176|            2|            2011|\n",
      "|          3.80|             |      192|           86|            2006|\n",
      "|          4.46|          eng|      192|            8|                |\n",
      "+--------------+-------------+---------+-------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select(df1.average_rating, df1.language_code, df1.num_pages, df1.ratings_count, df1.publication_year).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7a4b33-259f-4ae0-a051-0a01214b523e",
   "metadata": {},
   "source": [
    "* We will check the data types of dataframe's variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "16abbd7e-ed34-4cf9-8887-6e0f61711c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('asin', 'string'),\n",
       " ('authors', 'array<struct<author_id:string,role:string>>'),\n",
       " ('average_rating', 'string'),\n",
       " ('book_id', 'string'),\n",
       " ('country_code', 'string'),\n",
       " ('description', 'string'),\n",
       " ('edition_information', 'string'),\n",
       " ('format', 'string'),\n",
       " ('image_url', 'string'),\n",
       " ('is_ebook', 'string'),\n",
       " ('isbn', 'string'),\n",
       " ('isbn13', 'string'),\n",
       " ('kindle_asin', 'string'),\n",
       " ('language_code', 'string'),\n",
       " ('link', 'string'),\n",
       " ('num_pages', 'string'),\n",
       " ('popular_shelves', 'array<struct<count:string,name:string>>'),\n",
       " ('publication_day', 'string'),\n",
       " ('publication_month', 'string'),\n",
       " ('publication_year', 'string'),\n",
       " ('publisher', 'string'),\n",
       " ('ratings_count', 'string'),\n",
       " ('series', 'array<string>'),\n",
       " ('similar_books', 'array<string>'),\n",
       " ('text_reviews_count', 'string'),\n",
       " ('title', 'string'),\n",
       " ('title_without_series', 'string'),\n",
       " ('url', 'string'),\n",
       " ('work_id', 'string')]"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7684a149-620d-4bee-8b9a-5b31fd8932c9",
   "metadata": {},
   "source": [
    "* First of all, we will convert the datatypes of columns `average_rating`,`num_pages` & `ratings_count` from string to numeric type, in order to perfrom our calculations correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "9a667c69-858a-498a-84d0-3530a2245fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "df1 = df1.withColumn('average_rating',col('average_rating').cast('double'))\n",
    "df1 = df1.withColumn('num_pages',col('num_pages').cast('double'))\n",
    "df1 = df1.withColumn('ratings_count',col('ratings_count').cast('double'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc4f160-feee-4e13-ba00-0109c94831fb",
   "metadata": {},
   "source": [
    "* Create a new dataframe `df2` which contains only the variables that we will use for our regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "fb46aad3-820d-420b-bfbd-776dda5440f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+---------+-------------+----------------+\n",
      "|average_rating|language_code|num_pages|ratings_count|publication_year|\n",
      "+--------------+-------------+---------+-------------+----------------+\n",
      "|          4.12|             |     null|          1.0|                |\n",
      "|          3.94|          fre|     null|         16.0|            2016|\n",
      "|          4.28|          eng|    146.0|         51.0|            2012|\n",
      "|          4.05|          eng|     null|          6.0|                |\n",
      "|          4.06|        en-US|    272.0|         51.0|            1997|\n",
      "|          3.44|             |    206.0|         46.0|            2007|\n",
      "|          4.15|          eng|    224.0|         39.0|            2016|\n",
      "|          3.16|             |    160.0|         38.0|            2016|\n",
      "|          3.51|             |    160.0|         44.0|            2016|\n",
      "|           4.0|             |    144.0|         32.0|            2016|\n",
      "|          4.41|          kor|    212.0|        133.0|            2014|\n",
      "|          3.16|          eng|    144.0|        114.0|            2011|\n",
      "|          4.41|          eng|    200.0|        149.0|            2012|\n",
      "|          4.39|             |    230.0|        152.0|            2012|\n",
      "|          1.86|             |     null|         64.0|                |\n",
      "|          4.31|          jpn|    157.0|        174.0|            2013|\n",
      "|          4.43|          spa|    224.0|         30.0|            2006|\n",
      "|          4.38|          zho|    176.0|          2.0|            2011|\n",
      "|           3.8|             |    192.0|         86.0|            2006|\n",
      "|          4.46|          eng|    192.0|          8.0|                |\n",
      "+--------------+-------------+---------+-------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df1.select(df1.average_rating, df1.language_code, df1.num_pages, df1.ratings_count, df1.publication_year)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0deea96-81a9-4a04-9774-c779d423f246",
   "metadata": {},
   "source": [
    "* We will replace blank spaces in string variables (e.g., columns: `language_code` and `publication_year`) with \"unknown\" value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "cfa2a45e-bc26-46ed-ab73-7714fb56e451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+---------+-------------+----------------+\n",
      "|average_rating|language_code|num_pages|ratings_count|publication_year|\n",
      "+--------------+-------------+---------+-------------+----------------+\n",
      "|          4.12|      unknown|     null|          1.0|         unknown|\n",
      "|          3.94|          fre|     null|         16.0|            2016|\n",
      "|          4.28|          eng|    146.0|         51.0|            2012|\n",
      "|          4.05|          eng|     null|          6.0|         unknown|\n",
      "|          4.06|        en-US|    272.0|         51.0|            1997|\n",
      "|          3.44|      unknown|    206.0|         46.0|            2007|\n",
      "|          4.15|          eng|    224.0|         39.0|            2016|\n",
      "|          3.16|      unknown|    160.0|         38.0|            2016|\n",
      "|          3.51|      unknown|    160.0|         44.0|            2016|\n",
      "|           4.0|      unknown|    144.0|         32.0|            2016|\n",
      "|          4.41|          kor|    212.0|        133.0|            2014|\n",
      "|          3.16|          eng|    144.0|        114.0|            2011|\n",
      "|          4.41|          eng|    200.0|        149.0|            2012|\n",
      "|          4.39|      unknown|    230.0|        152.0|            2012|\n",
      "|          1.86|      unknown|     null|         64.0|         unknown|\n",
      "|          4.31|          jpn|    157.0|        174.0|            2013|\n",
      "|          4.43|          spa|    224.0|         30.0|            2006|\n",
      "|          4.38|          zho|    176.0|          2.0|            2011|\n",
      "|           3.8|      unknown|    192.0|         86.0|            2006|\n",
      "|          4.46|          eng|    192.0|          8.0|         unknown|\n",
      "+--------------+-------------+---------+-------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "replacements = {\n",
    "  'language_code': 'unknown', 'publication_year': 'unknown',\n",
    "  'numeric_column_wont_be_replaced': 1.0\n",
    "}\n",
    "\n",
    "for k, v in replacements.items():\n",
    "    if isinstance(v, str):\n",
    "        df2 = df2.na.replace(\"\", v, [k])\n",
    "\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bbdb7c-9794-41e2-90ef-3edd748c4ffe",
   "metadata": {},
   "source": [
    "* We will drop the rows which contain Nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "07389983-b5f9-4acb-bc6f-1fbde2214368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3617"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2.na.drop()\n",
    "df2.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c816ba-42bc-455b-a428-b2780e53edeb",
   "metadata": {},
   "source": [
    "## Train - Test split\n",
    "\n",
    "* We will split our dataset in train and test dataset. The train dataset will be the 70% of the original dataset, while the rest 30% will be the test dataset, according to which we will evaluate the predictive performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "f0ed83de-56f8-4155-943e-a2f27733a0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2490\n",
      "1127\n"
     ]
    }
   ],
   "source": [
    "trainDF, testDF = df2.randomSplit([0.7, 0.3], seed=3) #We use random seed so in every run we have the same split on train test.\n",
    "\n",
    "print(trainDF.cache().count()) #We use cache for efficiency (coumputational) reasons, as we will use the training set multiple times. \n",
    "\n",
    "print(testDF.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710c72e7-19a5-4443-8ee9-2b1b66e75041",
   "metadata": {},
   "source": [
    "* In this section, we will perform one hot encoding, which converts categorical variables into a set of numeric variables that only take on values 0 and 1. The variables that we will transform are `language_code` & `publication_year`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "eb80936d-722e-4886-bb10-f07f56343023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "\n",
    "# We define which columns are categorical\n",
    "categoricalCols = [\"language_code\" , \"publication_year\"]\n",
    "\n",
    "stringIndexer = StringIndexer(inputCols=categoricalCols, outputCols=[x + \"Index\" for x in categoricalCols]).setHandleInvalid(\"keep\") \n",
    "encoder = OneHotEncoder(inputCols=stringIndexer.getOutputCols(), outputCols=[x + \"OHE\" for x in categoricalCols]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "65d9c444-1fb2-4ab9-b67b-4ebbc29540a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+---------+-------------+----------------+------------------+---------------------+\n",
      "|average_rating|language_code|num_pages|ratings_count|publication_year|language_codeIndex|publication_yearIndex|\n",
      "+--------------+-------------+---------+-------------+----------------+------------------+---------------------+\n",
      "|           2.0|          ind|    128.0|          1.0|            2010|               4.0|                  6.0|\n",
      "|           2.0|      unknown|    144.0|          1.0|            2017|               1.0|                  9.0|\n",
      "|          2.35|      unknown|    104.0|         43.0|            2008|               1.0|                  8.0|\n",
      "|          2.55|      unknown|    128.0|         33.0|            2004|               1.0|                 14.0|\n",
      "|          2.59|      unknown|     96.0|         74.0|            2018|               1.0|                 36.0|\n",
      "|          2.67|      unknown|     64.0|         12.0|            2003|               1.0|                 15.0|\n",
      "|          2.81|      unknown|     96.0|         32.0|            1992|               1.0|                 30.0|\n",
      "+--------------+-------------+---------+-------------+----------------+------------------+---------------------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stringIndexerModel = stringIndexer.fit(trainDF)\n",
    "stringIndexerModel.transform(trainDF).show(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "a2d8e7d3-600c-4658-9a74-d14554593ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# This includes both the numeric columns and the one-hot encoded binary vector columns in our dataset.\n",
    "numericCols = [\"num_pages\", \"ratings_count\"]\n",
    "assemblerInputs = [c + \"OHE\" for c in categoricalCols] + numericCols\n",
    "vecAssembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "# With VectorAssembler transformer we create a single vector column from assemblerInputs which contains the numeric and the categorical (e.g., with one-hot encoded binary variables) columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9477483a-b4fa-4a44-bad7-0a95af9c5e3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Defining the model\n",
    "\n",
    "* In this section, we will define our predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "eb83ec33-ab2c-4162-b81d-709c970e635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='average_rating', regParam=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd587ea-083a-4528-9262-c8188f852295",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "* First, we will define the pipeline based on the stages created in previous steps (e.g., `stringIndexer`, `encoder`, `vecAssembler` and `lr`.)\n",
    "\n",
    "* Then we will define the pipeline model (e.g., `pipelineModel`).\n",
    "\n",
    "* Last, we will aplly the pipeline model to the test dataset (e.g., `testDF`) to predict the `average_rating`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "ff782542-d076-4cf9-9c72-67f9c50b0603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[stringIndexer, encoder, vecAssembler, lr])\n",
    "\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "predDF = pipelineModel.transform(testDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dfc778-688a-4275-adcf-d7754e66547e",
   "metadata": {},
   "source": [
    "* Now, we will display the predictions of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "5be9081c-9d27-45d2-9c19-23239ac2efd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+------------------+\n",
      "|            features|average_rating|        prediction|\n",
      "+--------------------+--------------+------------------+\n",
      "|(91,[1,42,89,90],...|          2.29|3.8669726947213894|\n",
      "|(91,[1,54,89,90],...|          2.33|3.9029502464881274|\n",
      "|(91,[1,39,89,90],...|          2.57| 3.864471457783849|\n",
      "|(91,[1,42,89,90],...|          2.57|3.8823523274618634|\n",
      "|(91,[0,42,89,90],...|          2.62| 3.908762360806099|\n",
      "+--------------------+--------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF.select(\"features\", \"average_rating\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b34fad-9b98-402b-b16d-8f086b9fe82f",
   "metadata": {},
   "source": [
    "* In order to evaluate the predictive performnace of our model, we will calculate the R Squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "7b93e02d-b37c-4ad9-a643-8efbc0f5cda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) on test data = 0.0419129\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"average_rating\",metricName=\"r2\")\n",
    "\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(predDF))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

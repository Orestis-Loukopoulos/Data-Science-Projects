# Assignment Solution Description

## Task A

To begin with, we imported the dataset in python. We used the pandas library in order to load the data in a data frame. Continuing, we performed some transformation on our data. First of all, we replaced the NaN values with None. Furthermore, we lower case every string of every column (i.e., authors venue, title), as we were advised to do so. Then, we observed that were some strings that contained some non-alphanumeric characters. For example, in the third row in the column of authors the string “norã©n”. So, with the help of some regular expressions we removed any non-alphanumeric character from strings. Continuing, we had to transform the way that strings appear in each column. We split them by the whitespace and add them to a list of words. For example, in the first row in the column title we had this string “11578 sorrento valley road” we split it by the whitespace and add it to a list of words. So, after the transformation the value looked like that “[11578, sorrento, valley, road]”. We did that for every string in every row for every column. 

After all of the above transformations we were ready to implement the Token Blocking technic. First, of all we initialized an empty dictionary. Each key of the dictionary will represent a token and each value of the key will contain the Entities in which this token has been found. Each key-value pair of the dictionary will represent a block. In order to fill this dictionary with keys and values, we used two for loops. One which iterates through the rows of the data frame, and one which iterates through the columns of the data frame. Then we were checking whether the value of each element of the data frame was of type list or not (we did that because in column year we had only numbers and not lists and we should handle - manage them differently). If it was of type list, we were iterating through the words – tokens of the list. Followingly, we were checking if the token already existed in the dictionary as a key, so as not to recreate blocks with the same keys (tokens). If the key already existed, we only append to the already created key the entity number in which the token was found. Finally, we pretty printed the keys of the blocks.

## Task B

In this task we had to compute all the possible comparisons, that had to be made in order to resolve the issue of duplicates within the blocks. In order to tackle that we iterate through the keys – tokens of each block. For every block, we calculated the number of entities that contains. We then apply the following formula in order to calculate the number of pairwise comparisons for each block: (n¦2) with n being equal to the number of entities each block contains. We append the result of this formula to a list for every block. By summarizing all these numbers, we calculated the total number of comparisons which was equal to approximately 2,8 Billions (2795570518).

## Task C

Continuing, we had to create a Meta-Blocking graph of the block collection using the CBS Weighting Scheme. Before we delve into more details regardless of the implementation of this task, we have to mention that for computational reasons we took only the first 10 blocks to carry out this task. 

To begin with, we first had to take all the combinations of entities for each block (these combinations represent the edges between the entities-nodes). Specifically, for each token (key) in the blocks dictionary, we found all the possible combinations of entities and append it to a list. This list represents the existing edges between Entities. We should mention that this list is a list of lists which contains tuples. Each tuple is a pair of entities that appear in the same block. Continuing, we append each tuple into a new list, so the new list contains all the pairs of entities (something like an edge list). Then we added the weights to the edges (pair of entities) based on the number of blocks the pair of entities appear together. So, now we have created a weighted edge list. Furthermore, we created a graph, based on the weighted edge list we created before. After creating the graph, we filtered out all the edges that have weight lower than 2 (i.e., edge pruning). We then recalculated the number of comparisons of the new block collection after the edge pruning, by summarizing the number of entity pairs (edges) that have weight greater than or equal to 2. The total number of comparisons for the first 10 blocks after the pruning is equal to 305845.

## Task D

In the final task, we created a function that calculates the Jaccard similarity between two entities based on the title column. This function takes as input the index of a pair of entities (i.e., Entity 1 has index = 1) and returns their Jaccard Similarity based on the entities’ title attribute. 
